{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b11292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e4f95",
   "metadata": {},
   "source": [
    "### üì¶ Importing OpenCV and MediaPipe\n",
    "\n",
    "Here, we‚Äôre loading two essential libraries for computer vision tasks:\n",
    "\n",
    "- **cv2**: This is from OpenCV. It lets you handle videos, capture frames, display images, and do all kinds of visual processing. Super flexible and fast. üé•\n",
    "\n",
    "- **mediapipe**: Shortened as `mp`, this one‚Äôs made by Google. It gives you powerful, pre-trained models for real-time body tracking, hand detection, face meshes, and more. Perfect for stuff like pose estimation or gesture-based interactions. ü§ñ\n",
    "\n",
    "In short: you‚Äôre getting all the tools ready to watch a video and track human movement like a pro. üí™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video_path :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af2dc3",
   "metadata": {},
   "source": [
    "### üé¨ Capturing the Video\n",
    "\n",
    "Here, you're setting up video capture using OpenCV:\n",
    "\n",
    "- `cv2.VideoCapture('video_path :)')` initializes the video stream.\n",
    "- The `'video_path :)'` is a placeholder ‚Äî you'll replace it with the actual path to your video file, like `'my_video.mp4'`.\n",
    "- Once that's done, the `cap` object will let you read each frame of the video one at a time.\n",
    "\n",
    "Basically, you‚Äôre opening the door to your video content ‚Äî frame by frame. üß©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "posList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3de4a6",
   "metadata": {},
   "source": [
    "### üß† Setting Up MediaPipe Pose Detection\n",
    "\n",
    "Now it's time to prep the tools for detecting human poses:\n",
    "\n",
    "- `mp.solutions.pose` gives you access to MediaPipe‚Äôs pose detection module.\n",
    "- `mp_pose.Pose()` creates an instance of the pose tracker ‚Äî this is what will analyze each video frame and find key body landmarks (like shoulders, elbows, knees, etc).\n",
    "- `mp.solutions.drawing_utils` is used to draw those detected landmarks and connections right on the video frames. Super handy for visualizing results. üéØ\n",
    "- `posList = []` is just an empty list for now ‚Äî later on, you‚Äôll fill it with the coordinates of the detected pose landmarks.\n",
    "\n",
    "You're basically loading the AI brain and prepping a space to store what it sees. üîç\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec016d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True :\n",
    "    success, img = cap.read()\n",
    "    if not success :\n",
    "        break\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(img_rgb)\n",
    "        \n",
    "    if results.pose_landmarks :\n",
    "        lmString = ''\n",
    "        h, w, _ = img.shape\n",
    "        for lm in results.pose_landmarks.landmark :\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            lmString += f'{cx},{h - cy},'\n",
    "\n",
    "        posList.append(lmString)\n",
    "        print(len(posList))\n",
    "\n",
    "        mp_draw.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord('s') :\n",
    "        with open('AnimationFile.txt', 'w') as f :\n",
    "            f.writelines(['%s\\n' % item for item in posList])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04fd752",
   "metadata": {},
   "source": [
    "### üîÑ Main Loop: Reading, Detecting, and Storing Pose Data\n",
    "\n",
    "This `while True` loop is the core of the program ‚Äî it runs continuously to process each video frame:\n",
    "\n",
    "- **`cap.read()`** reads the next frame from the video. If there‚Äôs nothing left (video ends or error), the loop breaks.\n",
    "- The frame is converted from BGR to RGB (`cv2.cvtColor`) because MediaPipe expects RGB images.\n",
    "- `pose.process(img_rgb)` runs the pose detection model and returns landmark results.\n",
    "\n",
    "If landmarks are detected:\n",
    "\n",
    "- An empty string `lmString` is created to hold the landmark positions for this frame.\n",
    "- For each landmark, the `(x, y)` coordinates are scaled to the actual image size.\n",
    "- Y-values are flipped (`h - cy`) ‚Äî probably for compatibility with a different coordinate system (like in animation engines).\n",
    "- This comma-separated string is added to `posList`.\n",
    "\n",
    "Other actions:\n",
    "\n",
    "- `draw_landmarks()` visualizes the landmarks on the image so you can see what's being tracked.\n",
    "- The frame is shown using `cv2.imshow()`.\n",
    "- If the user presses the **`s` key**, all recorded positions are saved into `AnimationFile.txt`, and the loop exits.\n",
    "\n",
    "üé• In short: you're reading video, detecting body landmarks in real-time, showing the result live, and saving the data when needed. Pretty slick!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac56365",
   "metadata": {},
   "source": [
    "### üõë Cleanup: Releasing Resources\n",
    "\n",
    "After you‚Äôre done processing the video:\n",
    "\n",
    "- `cap.release()` frees up the video capture object ‚Äî basically closing the video file and releasing the camera or file handle.\n",
    "- `cv2.destroyAllWindows()` shuts down all the OpenCV windows you opened (like the live video display).\n",
    "\n",
    "This part is super important to avoid locking files or freezing windows once your program finishes. Smooth exit vibes! ‚úåÔ∏è\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
